# HyperParameter Tuning With Microsoft Neural Network Intelligence: *PROJECT 6*
### 1 - Uuse the popular MNIST dataset and train a simple Neural Network to learn to classify images of hand-written digits from the dataset. 
### 2 -Once a basic script is in place, we will use the NNI toolkit to run a hyperparameter tuning experiment to find optimal values for batch size, learning rate, choice of activation function for the hidden layer, number of hidden units for the hidden layer, and dropout rate for the dropout layer.
![HyperParameterTuning](https://user-images.githubusercontent.com/106122834/182059838-6ed7c8b6-c6e9-424a-9a08-2a630f4c7c4d.jpeg)
![Page-1  Coursera GBYM6XPGH7Y4 pdf](https://user-images.githubusercontent.com/106122834/182059845-147ff1ff-91d5-46fb-93fe-888136355e09.jpeg)
